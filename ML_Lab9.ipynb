{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e102948d-7f64-4709-86c7-5c909c1c328c",
   "metadata": {},
   "source": [
    "**Practical-9**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387eb33f-ac50-4ded-b675-3a1e1b6b70bb",
   "metadata": {},
   "source": [
    "**Aim: Implement Ex-OR Gate/any other problem using Backpropagation Neural Networks (Self-Implementation)**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1653acf-c926-46d0-846c-bb4c95810e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final predictions:\n",
      "[[0.007]\n",
      " [0.994]\n",
      " [0.994]\n",
      " [0.006]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# XOR input and output\n",
    "X = np.array([[0,0],\n",
    "              [0,1],\n",
    "              [1,0],\n",
    "              [1,1]])\n",
    "\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])\n",
    "\n",
    "# Activation function\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    # x is already sigmoid(x)\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Initialize weights\n",
    "np.random.seed(42)\n",
    "w1 = np.random.uniform(size=(2, 2))   # input to hidden\n",
    "b1 = np.random.uniform(size=(1, 2))   # hidden bias\n",
    "w2 = np.random.uniform(size=(2, 1))   # hidden to output\n",
    "b2 = np.random.uniform(size=(1, 1))   # output bias\n",
    "\n",
    "lr = 0.15  # learning rate\n",
    "epochs = 200000\n",
    "\n",
    "# Training loop (backpropagation)\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Forward pass\n",
    "    z1 = np.dot(X, w1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "\n",
    "    z2 = np.dot(a1, w2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    # Error\n",
    "    error = y - a2\n",
    "\n",
    "    # Backpropagation\n",
    "    d_a2 = error * sigmoid_derivative(a2)\n",
    "    d_w2 = np.dot(a1.T, d_a2)\n",
    "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
    "\n",
    "    d_a1 = np.dot(d_a2, w2.T) * sigmoid_derivative(a1)\n",
    "    d_w1 = np.dot(X.T, d_a1)\n",
    "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
    "\n",
    "    # Update weights\n",
    "    w1 += lr * d_w1\n",
    "    b1 += lr * d_b1\n",
    "    w2 += lr * d_w2\n",
    "    b2 += lr * d_b2\n",
    "\n",
    "# Final output after training\n",
    "print(\"Final predictions:\")\n",
    "print(a2.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1448859-411e-4ed9-a562-6712ce798ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.2566\n",
      "Epoch 2000 | Loss: 0.1819\n",
      "Epoch 4000 | Loss: 0.0157\n",
      "Epoch 6000 | Loss: 0.0048\n",
      "Epoch 8000 | Loss: 0.0027\n",
      "\n",
      "XOR Predictions:\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# XOR dataset\n",
    "X = np.array([[0,0],\n",
    "              [0,1],\n",
    "              [1,0],\n",
    "              [1,1]])\n",
    "\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])\n",
    "\n",
    "# Sigmoid activation\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(a):\n",
    "    return a * (1 - a)\n",
    "\n",
    "# Neural Network Training\n",
    "def train_XOR(X, y, hidden_units=2, lr=0.5, epochs=10000):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    n_x = 2\n",
    "    n_h = hidden_units\n",
    "    n_y = 1\n",
    "    \n",
    "    # Initialize weights\n",
    "    W1 = np.random.randn(n_h, n_x)\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h)\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Forward pass\n",
    "        Z1 = np.dot(W1, X.T) + b1\n",
    "        A1 = sigmoid(Z1)\n",
    "\n",
    "        Z2 = np.dot(W2, A1) + b2\n",
    "        A2 = sigmoid(Z2)\n",
    "\n",
    "        # Compute loss\n",
    "        m = y.shape[0]\n",
    "        loss = np.mean((y.T - A2)**2)\n",
    "\n",
    "        # Backpropagation\n",
    "        dZ2 = (A2 - y.T) * sigmoid_derivative(A2)\n",
    "        dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "        db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "        dZ1 = np.dot(W2.T, dZ2) * sigmoid_derivative(A1)\n",
    "        dW1 = (1/m) * np.dot(dZ1, X)\n",
    "        db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "        # Update weights\n",
    "        W1 -= lr * dW1\n",
    "        b1 -= lr * db1\n",
    "        W2 -= lr * dW2\n",
    "        b2 -= lr * db2\n",
    "\n",
    "        if i % 2000 == 0:\n",
    "            print(f\"Epoch {i} | Loss: {loss:.4f}\")\n",
    "\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# Prediction\n",
    "def predict(X, W1, b1, W2, b2):\n",
    "    Z1 = np.dot(W1, X.T) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    return (A2 > 0.5).astype(int)\n",
    "\n",
    "# Train XOR model\n",
    "W1, b1, W2, b2 = train_XOR(X, y)\n",
    "\n",
    "# Test\n",
    "preds = predict(X, W1, b1, W2, b2)\n",
    "\n",
    "print(\"\\nXOR Predictions:\")\n",
    "print(preds.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc2c32c-2787-4e34-94dd-47444f886993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.7065\n",
      "Epoch 2000 | Loss: 0.6043\n",
      "Epoch 4000 | Loss: 0.1989\n",
      "Epoch 6000 | Loss: 0.0469\n",
      "Epoch 8000 | Loss: 0.0247\n",
      "\n",
      "XOR Predictions:\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# XOR dataset\n",
    "X = np.array([[0,0],\n",
    "              [0,1],\n",
    "              [1,0],\n",
    "              [1,1]])        # shape = (4,2)\n",
    "\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])         # shape = (4,1)\n",
    "\n",
    "# Sigmoid activation\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(a):\n",
    "    return a * (1 - a)\n",
    "\n",
    "# Binary Cross-Entropy (Logit Loss)\n",
    "def logit_loss(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    return -np.mean(y * np.log(y_hat + 1e-8) + (1 - y) * np.log(1 - y_hat + 1e-8))\n",
    "\n",
    "# Neural Network Training\n",
    "def train_XOR_logit(X, y, hidden_units=2, lr=0.1, epochs=10000):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    n_x = 2\n",
    "    n_h = hidden_units\n",
    "    n_y = 1\n",
    "    \n",
    "    # Initialize weights\n",
    "    W1 = np.random.randn(n_h, n_x)\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h)\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "\n",
    "    m = y.shape[0]\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Forward pass\n",
    "        Z1 = np.dot(W1, X.T) + b1\n",
    "        A1 = sigmoid(Z1)\n",
    "\n",
    "        Z2 = np.dot(W2, A1) + b2\n",
    "        A2 = sigmoid(Z2)\n",
    "\n",
    "        # Compute logit loss\n",
    "        loss = logit_loss(y, A2.T)\n",
    "\n",
    "        # Backpropagation using BCE derivatives\n",
    "        dZ2 = A2 - y.T              # derivative of BCE for sigmoid\n",
    "        dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "        db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "        dZ1 = np.dot(W2.T, dZ2) * sigmoid_derivative(A1)\n",
    "        dW1 = (1/m) * np.dot(dZ1, X)\n",
    "        db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "        # Update parameters\n",
    "        W1 -= lr * dW1\n",
    "        b1 -= lr * db1\n",
    "        W2 -= lr * dW2\n",
    "        b2 -= lr * db2\n",
    "\n",
    "        if i % 2000 == 0:\n",
    "            print(f\"Epoch {i} | Loss: {loss:.4f}\")\n",
    "\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# Prediction\n",
    "def predict(X, W1, b1, W2, b2):\n",
    "    Z1 = np.dot(W1, X.T) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    return (A2 > 0.5).astype(int)\n",
    "\n",
    "# Train XOR model with Logit Loss\n",
    "W1, b1, W2, b2 = train_XOR_logit(X, y)\n",
    "\n",
    "# Test\n",
    "preds = predict(X, W1, b1, W2, b2)\n",
    "\n",
    "print(\"\\nXOR Predictions:\")\n",
    "print(preds.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdaf80c-eeaf-4968-b5c9-5262fb55008e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
